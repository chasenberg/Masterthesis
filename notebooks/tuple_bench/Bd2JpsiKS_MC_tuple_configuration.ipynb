{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import ROOT\n",
    "from rootpy.tree import Tree, TreeModel, FloatCol, IntCol\n",
    "from rootpy.io import root_open\n",
    "from ROOT import gROOT, TCanvas, TF1, TFile, TTree, gRandom, TH1F\n",
    "\n",
    "from ROOT import RooRealVar, RooFormulaVar, RooVoigtian, RooChebychev, RooArgList, \\\n",
    "                 RooArgSet, RooAddPdf, RooDataSet, RooCategory, RooSimultaneous, \\\n",
    "                 RooBreitWigner, RooCBShape, RooFFTConvPdf, RooGaussian,RooExponential, \\\n",
    "                 RooBinning, kRed, kBlue, kDotted,TString,RooAbsData, RooPlot, TCut, RooAbsData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/rh/miniconda/envs/py3root6/lib/python3.4/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os, sys, time, random\n",
    "\n",
    "from ROOT import TTree, TFile\n",
    "\n",
    "# from root_numpy import root2array, rec2array, array2root\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy \n",
    "import root_pandas as rp\n",
    "import root_numpy as ry \n",
    "\n",
    "import pandas.core.common as com\n",
    "from pandas.core.index import Index\n",
    "from pandas.tools import plotting\n",
    "from pandas.tools.plotting import scatter_matrix\n",
    "\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.preprocessing import Imputer, StandardScaler\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.metrics import classification_report, roc_curve, auc, roc_auc_score\n",
    "\n",
    "sys.path.append('/home/chasenberg/repos/')\n",
    "sys.path.append('/home/chasenberg/repos/dopy')\n",
    "from dopy import * \n",
    "from dopy.dolearn.sklearn_utils import plot_roc_curve, plot_classifier_output, plot_correlations\n",
    "from dopy.dolearn.sklearn_utils import plot_feature_importances, plot_classifier_output, classify_unseen_data\n",
    "#from dopy.sklearn_utils import plot_bdt_vars\n",
    "from dopy.doplot.plotting import Plotter, Plot\n",
    "from dopy.doanalysis.df_utils import add_min_max, add_eta "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create new ROOT File with relevant branches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Names of the produced tuples\n",
    "mc_dir_2015_2016 = '/fhgfs/users/chasenberg/mc/2015_2016_merged/jpsimumuks/'\n",
    "mc_sanity_cuts = 'Bd2JpsiKS_sanity.root'\n",
    "mc_bestPV = 'Bd2JpsiKS_bestPV.root'\n",
    "mc_random = 'Bd2JpsiKS_random.root'\n",
    "mc_selected = 'Bd2JpsiKS_selected.root'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cut_string = 'B0_FitDaughtersConst_status==0&B0_FitPVConst_status==0&B0_BKGCAT==0&(B0_L0MuonDecision_Dec==1|B0_L0DiMuonDecision_Dec==1|B0_L0MuonHighDecision_Dec==1)&(B0_Hlt1DiMuonHighMassDecision_Dec==1|B0_Hlt1TrackMVADecision_Dec==1)&(B0_Hlt1DiMuonHighMassDecision_Dec==1|B0_Hlt1TrackMVADecision_Dec==1)&(B0_Hlt2DiMuonJPsiDecision_Dec==1|B0_Hlt2DiMuonDetachedJPsiDecision_Dec==1)'               \n",
    "tree_mc = 'Bd2JpsiKs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "calculate_trigger_efficiency = True \n",
    "create_sanity_tuple = True\n",
    "#create_bestPV_tuple = True\n",
    "create_randomSel_tuple = True\n",
    "create_training_tuple = False\n",
    "create_l0veto_tuple = True\n",
    "#do_sanity_massfit = True\n",
    "#do_bestPV_massfit = True \n",
    "#do_randomPV_massfit = True "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "variables = [\n",
    "#Flavour tagging\n",
    "'B0_TAGOMEGA_OS',\n",
    "'B0_TAGDECISION_OS',\n",
    "#Mass and kinematics -> Constrained daughters\n",
    "'B0_FitDaughtersConst_status_flat',\n",
    "'B0_FitDaughtersConst_M_flat',\n",
    "'B0_FitDaughtersConst_chi2_flat',\n",
    "'B0_FitDaughtersConst_IPCHI2_flat',\n",
    "'B0_FitDaughtersConst_nDOF_flat',\n",
    "'B0_FitDaughtersConst_PT_flat',\n",
    "#Jpsi\n",
    "'B0_FitDaughtersConst_J_psi_1S_P0_PT_flat', \n",
    "'B0_FitDaughtersConst_J_psi_1S_P1_PT_flat',\n",
    "'B0_FitDaughtersConst_J_psi_1S_MinIPCHI2anyPV_flat',\n",
    "'B0_FitDaughtersConst_J_psi_1S_IPCHI2_flat',\n",
    "'B0_FitDaughtersConst_J_psi_1S_IP_flat', \n",
    "#KS0\n",
    "'B0_FitDaughtersConst_KS0_P1_PT_flat', \n",
    "'B0_FitDaughtersConst_KS0_P0_PT_flat',\n",
    "'B0_FitDaughtersConst_KS0_MinIPCHI2anyPV',  \n",
    "'B0_FitDaughtersConst_KS0_P0_IPCHI2_flat', \n",
    "'B0_FitDaughtersConst_KS0_P1_IPCHI2_flat',\n",
    "'B0_FitDaughtersConst_KS0_decayLength_flat',\n",
    "'B0_FitDaughtersConst_KS0_IP_flat',\n",
    "\n",
    "#Mass and kinematics -> Constrained pv\n",
    "'B0_FitPVConst_status_flat',\n",
    "'B0_FitPVConst_IPCHI2_flat',\n",
    "'B0_FitPVConst_chi2_flat',\n",
    "'B0_FitPVConst_nDOF_flat',\n",
    "'B0_FitPVConst_tauErr_flat',\n",
    "'B0_FitPVConst_tau_flat',\n",
    "'B0_FitPVConst_MinIPCHI2anyPV_flat',\n",
    "'B0_FitPVConst_PV_Z_flat',\n",
    "'B0_FitPVConst_X_flat',\n",
    "'B0_FitPVConst_Y_flat',\n",
    "'B0_FitPVConst_Z_flat',\n",
    "'B0_FitPVConst_XERR_flat',\n",
    "'B0_FitPVConst_YERR_flat',\n",
    "'B0_FitPVConst_ZERR_flat',\n",
    "#Jpsi\n",
    "'B0_FitPVConst_J_psi_1S_MinIPCHI2anyPV_flat',\n",
    "'B0_FitPVConst_J_psi_1S_IP_flat',\n",
    "'B0_FitPVConst_J_psi_1S_IPCHI2_flat',\n",
    "#KS0\n",
    "'B0_FitPVConst_KS0_MinIPCHI2anyPV_flat',\n",
    "'B0_FitPVConst_KS0_IP_flat',\n",
    "'B0_FitPVConst_KS0_IPCHI2_flat',\n",
    "'B0_FitPVConst_KS0_tau_flat',\n",
    "'B0_FitPVConst_KS0_tauErr_flat',\n",
    "\n",
    "# Other DTF stuff\n",
    "'B0_FitJpsiPVConst_Z_flat',\n",
    "'B0_FitJpsiConst_J_psi_1S_MinIPCHI2anyPV_flat',\n",
    "'B0_FitSubstPVKpi1_KS0_MinIPCHI2anyPV',\n",
    "#Random variables from Loki functors\n",
    "'B0_BKGCAT',\n",
    "'B0_TRUETAU',\n",
    "'B0_TAU',\n",
    "'B0_TAUERR',\n",
    "'B0_MINIPCHI2',\n",
    "'pv_z_pull',\n",
    "'piplus_TRACK_Type',\n",
    "'piminus_MINIPCHI2',\n",
    "'piplus_MINIPCHI2',\n",
    "'muminus_MINIPCHI2',\n",
    "'muplus_MINIPCHI2',\n",
    "'piplus_ProbNNp',\n",
    "'piminus_ProbNNp',\n",
    "'varLambda0MassHypo_ppluspiminus',\n",
    "'varLambda0MassHypo_pminuspiplus',\n",
    "'eventNumber',\n",
    "'runNumber',\n",
    "'B0_FitwithoutConst_chi2',\n",
    "'B0_FitwithoutConst_nDOF',\n",
    "'B0_LOKI_ETA',\n",
    "'B0_LOKI_PHI',\n",
    "'nPV',\n",
    "'nTracks',\n",
    "'idxPV',\n",
    "'piplus_TRACK_Type',\n",
    "'B0_TRUEID'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#variables = 'B0_FitPVConst_IPCHI2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sanity_cuts = 'B0_FitDaughtersConst_status==0&B0_FitPVConst_status==0&B0_BKGCAT==0'\n",
    "trigger = '&(B0_L0MuonDecision_Dec==1|B0_L0DiMuonDecision_Dec==1|B0_L0MuonHighDecision_Dec==1)&(B0_Hlt1DiMuonHighMassDecision_Dec==1|B0_Hlt1TrackMVADecision_Dec==1)&(B0_Hlt1DiMuonHighMassDecision_Dec==1|B0_Hlt1TrackMVADecision_Dec==1)&(B0_Hlt2DiMuonJPsiDecision_Dec==1|B0_Hlt2DiMuonDetachedJPsiDecision_Dec==1)'\n",
    "cut = sanity_cuts+trigger\n",
    "tree_data ='Bd2JpsiKs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "l0_cut = 'B0_FitDaughtersConst_status==0&B0_FitPVConst_status==0&B0_BKGCAT==0&(B0_L0MuonDecision_Dec==1|B0_L0DiMuonDecision_Dec==1|B0_L0MuonHighDecision_Dec==1)'\n",
    "hlt1_cut = 'B0_FitDaughtersConst_status==0&B0_FitPVConst_status==0&B0_BKGCAT==0&(B0_Hlt1DiMuonHighMassDecision_Dec==1|B0_Hlt1TrackMVADecision_Dec==1)'\n",
    "hlt2_cut = 'B0_FitDaughtersConst_status==0&B0_FitPVConst_status==0&B0_BKGCAT==0&(B0_Hlt2DiMuonJPsiDecision_Dec==1)'#|B0_Hlt2DiMuonDetachedJPsiDecision_Dec==1)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading 2015 mc.\n",
      "The shape of 2015 mc is: (831240, 1)\n",
      "Reading 2016 mc.\n",
      "The shape of 2016 mc is: (828722, 1)\n",
      "Merging 2015+2016 mc..\n",
      "Reading 2015 mc.\n",
      "The shape of 2015 mc is: (693869, 2)\n",
      "Reading 2016 mc.\n",
      "The shape of 2016 mc is: (692670, 2)\n",
      "Merging 2015+2016 mc..\n",
      "Reading 2015 mc.\n",
      "The shape of 2015 mc is: (524367, 2)\n",
      "Reading 2016 mc.\n",
      "The shape of 2016 mc is: (578374, 2)\n",
      "Merging 2015+2016 mc..\n",
      "Reading 2015 mc.\n",
      "The shape of 2015 mc is: (537903, 2)\n",
      "Reading 2016 mc.\n",
      "The shape of 2016 mc is: (562651, 2)\n",
      "Merging 2015+2016 mc..\n",
      "Reading 2015 mc.\n",
      "The shape of 2015 mc is: (594891, 2)\n",
      "Reading 2016 mc.\n",
      "The shape of 2016 mc is: (599875, 2)\n",
      "Merging 2015+2016 mc..\n",
      "Reading 2015 mc.\n",
      "The shape of 2015 mc is: (497704, 2)\n",
      "Reading 2016 mc.\n",
      "The shape of 2016 mc is: (546347, 2)\n",
      "Merging 2015+2016 mc..\n",
      "the efficiency of the sanity cuts is\n",
      "0.8352835787807191\n",
      "------------------------------------\n",
      "the efficiency of the trigger requirements is:\n",
      "0.7529907200590824\n",
      "DD:\n",
      "0.7492154156407738\n",
      "LL:\n",
      "0.7629577512857334\n",
      "--------------------------------------\n",
      "The efficiencies of the single trigger stages are:\n",
      "L0\n",
      "the efficiency of the trigger requirements is:\n",
      "0.7953191363531786\n",
      "DD:\n",
      "0.7958797885500404\n",
      "LL:\n",
      "0.7938389807592849\n",
      "------------------------------------\n",
      "HLT1\n",
      "the efficiency of the trigger requirements is:\n",
      "0.7937418276730767\n",
      "DD:\n",
      "0.789004482770965\n",
      "LL:\n",
      "0.8062487037654466\n",
      "------------------------------------\n",
      "HLT2\n",
      "the efficiency of the trigger requirements is:\n",
      "0.8616894295796945\n",
      "DD:\n",
      "0.8622293730882593\n",
      "LL:\n",
      "0.8602639461711529\n",
      "------------------------------------\n",
      "the efficiency of the sanity cuts is\n",
      "0.8352835787807191\n",
      "------------------------------------\n",
      "the efficiency of the trigger requirements is:\n",
      "0.7529907200590824\n",
      "DD:\n",
      "0.7492154156407738\n",
      "LL:\n",
      "0.7629577512857334\n",
      "--------------------------------------\n",
      "The efficiencies of the single trigger stages are:\n",
      "L0\n",
      "the efficiency of the trigger requirements is:\n",
      "0.7953191363531786\n",
      "DD:\n",
      "0.7958797885500404\n",
      "LL:\n",
      "0.7938389807592849\n",
      "------------------------------------\n",
      "HLT1\n",
      "the efficiency of the trigger requirements is:\n",
      "0.7937418276730767\n",
      "DD:\n",
      "0.789004482770965\n",
      "LL:\n",
      "0.8062487037654466\n",
      "------------------------------------\n",
      "HLT2\n",
      "the efficiency of the trigger requirements is:\n",
      "0.8616894295796945\n",
      "DD:\n",
      "0.8622293730882593\n",
      "LL:\n",
      "0.8602639461711529\n",
      "------------------------------------\n"
     ]
    }
   ],
   "source": [
    "if calculate_trigger_efficiency==True:\n",
    "    mc_file_2015 = 'Bd2JpsimumuKS_mc_2015_flat.root'\n",
    "    mc_dir_2015 = '/fhgfs/users/chasenberg/mc/2015/jpsimumuks/'\n",
    "    mc_2015 = mc_dir_2015 + mc_file_2015\n",
    "    #read from ROOT-fil\n",
    "    print(\"Reading 2015 mc.\")\n",
    "    df_2015 = rp.read_root(mc_2015,key=tree_data, columns='B0_FitDaughtersConst_M_flat', flatten=False)\n",
    "    df_2015 = df_2015.replace([np.inf, -np.inf], np.nan)\n",
    "    df_2015 = df_2015.dropna()\n",
    "    print(\"The shape of 2015 mc is:\",df_2015.shape)\n",
    "    #directories and files for 2015\n",
    "    mc_file_2016 = 'Bd2JpsimumuKS_mc_2016_flat.root'\n",
    "    mc_dir_2016 = '/fhgfs/users/chasenberg/mc/2016/jpsimumuks/'\n",
    "    mc_2016 = mc_dir_2016 + mc_file_2016\n",
    "    #read from ROOT-file\n",
    "    print(\"Reading 2016 mc.\")\n",
    "    df_2016 = rp.read_root(mc_2016,key=tree_data, columns='B0_FitDaughtersConst_M_flat', flatten=False)\n",
    "    df_2016 = df_2016.replace([np.inf, -np.inf], np.nan)\n",
    "    df_2016 = df_2016.dropna()\n",
    "    print(\"The shape of 2016 mc is:\",df_2016.shape)\n",
    "    print(\"Merging 2015+2016 mc..\")\n",
    "    df_merged_nocut = pd.concat([df_2015,df_2016])\n",
    "    \n",
    "    mc_file_2015 = 'Bd2JpsimumuKS_mc_2015_flat.root'\n",
    "    mc_dir_2015 = '/fhgfs/users/chasenberg/mc/2015/jpsimumuks/'\n",
    "    mc_2015 = mc_dir_2015 + mc_file_2015\n",
    "    #read from ROOT-fil\n",
    "    print(\"Reading 2015 mc.\")\n",
    "    df_2015 = rp.read_root(mc_2015,key=tree_data, columns=['B0_FitDaughtersConst_M_flat','piplus_TRACK_Type'], where=sanity_cuts, flatten=False)\n",
    "    df_2015 = df_2015.replace([np.inf, -np.inf], np.nan)\n",
    "    df_2015 = df_2015.dropna()\n",
    "    print(\"The shape of 2015 mc is:\",df_2015.shape)\n",
    "    #directories and files for 2015\n",
    "    mc_file_2016 = 'Bd2JpsimumuKS_mc_2016_flat.root'\n",
    "    mc_dir_2016 = '/fhgfs/users/chasenberg/mc/2016/jpsimumuks/'\n",
    "    mc_2016 = mc_dir_2016 + mc_file_2016\n",
    "    #read from ROOT-file\n",
    "    print(\"Reading 2016 mc.\")\n",
    "    df_2016 = rp.read_root(mc_2016,key=tree_data, columns=['B0_FitDaughtersConst_M_flat','piplus_TRACK_Type'], where=sanity_cuts,flatten=False)\n",
    "    df_2016 = df_2016.replace([np.inf, -np.inf], np.nan)\n",
    "    df_2016 = df_2016.dropna()\n",
    "    print(\"The shape of 2016 mc is:\",df_2016.shape)\n",
    "    print(\"Merging 2015+2016 mc..\")\n",
    "    df_merged_sanity = pd.concat([df_2015,df_2016])\n",
    "    \n",
    "    ##Check efficiencies of L0 stage\n",
    "    mc_file_2015 = 'Bd2JpsimumuKS_mc_2015_flat.root'\n",
    "    mc_dir_2015 = '/fhgfs/users/chasenberg/mc/2015/jpsimumuks/'\n",
    "    mc_2015 = mc_dir_2015 + mc_file_2015\n",
    "    #read from ROOT-fil\n",
    "    print(\"Reading 2015 mc.\")\n",
    "    df_2015 = rp.read_root(mc_2015,key=tree_data, columns=['B0_FitDaughtersConst_M_flat','piplus_TRACK_Type'], where=l0_cut, flatten=False)\n",
    "    df_2015 = df_2015.replace([np.inf, -np.inf], np.nan)\n",
    "    df_2015 = df_2015.dropna()\n",
    "    print(\"The shape of 2015 mc is:\",df_2015.shape)\n",
    "    #directories and files for 2015\n",
    "    mc_file_2016 = 'Bd2JpsimumuKS_mc_2016_flat.root'\n",
    "    mc_dir_2016 = '/fhgfs/users/chasenberg/mc/2016/jpsimumuks/'\n",
    "    mc_2016 = mc_dir_2016 + mc_file_2016\n",
    "    #read from ROOT-file\n",
    "    print(\"Reading 2016 mc.\")\n",
    "    df_2016 = rp.read_root(mc_2016,key=tree_data, columns=['B0_FitDaughtersConst_M_flat','piplus_TRACK_Type'], where=l0_cut,flatten=False)\n",
    "    df_2016 = df_2016.replace([np.inf, -np.inf], np.nan)\n",
    "    df_2016 = df_2016.dropna()\n",
    "    print(\"The shape of 2016 mc is:\",df_2016.shape)\n",
    "    print(\"Merging 2015+2016 mc..\")\n",
    "    df_merged_l0= pd.concat([df_2015,df_2016])\n",
    "\n",
    "    \n",
    "    ##Check efficiencies of HLT1 stage\n",
    "    mc_file_2015 = 'Bd2JpsimumuKS_mc_2015_flat.root'\n",
    "    mc_dir_2015 = '/fhgfs/users/chasenberg/mc/2015/jpsimumuks/'\n",
    "    mc_2015 = mc_dir_2015 + mc_file_2015\n",
    "    #read from ROOT-fil\n",
    "    print(\"Reading 2015 mc.\")\n",
    "    df_2015 = rp.read_root(mc_2015,key=tree_data, columns=['B0_FitDaughtersConst_M_flat','piplus_TRACK_Type'], where=hlt1_cut, flatten=False)\n",
    "    df_2015 = df_2015.replace([np.inf, -np.inf], np.nan)\n",
    "    df_2015 = df_2015.dropna()\n",
    "    print(\"The shape of 2015 mc is:\",df_2015.shape)\n",
    "    #directories and files for 2015\n",
    "    mc_file_2016 = 'Bd2JpsimumuKS_mc_2016_flat.root'\n",
    "    mc_dir_2016 = '/fhgfs/users/chasenberg/mc/2016/jpsimumuks/'\n",
    "    mc_2016 = mc_dir_2016 + mc_file_2016\n",
    "    #read from ROOT-file\n",
    "    print(\"Reading 2016 mc.\")\n",
    "    df_2016 = rp.read_root(mc_2016,key=tree_data, columns=['B0_FitDaughtersConst_M_flat','piplus_TRACK_Type'], where=hlt1_cut,flatten=False)\n",
    "    df_2016 = df_2016.replace([np.inf, -np.inf], np.nan)\n",
    "    df_2016 = df_2016.dropna()\n",
    "    print(\"The shape of 2016 mc is:\",df_2016.shape)\n",
    "    print(\"Merging 2015+2016 mc..\")\n",
    "    df_merged_hlt1 = pd.concat([df_2015,df_2016])\n",
    "    \n",
    "    ##Check efficiencies of HLT2 stage\n",
    "    mc_file_2015 = 'Bd2JpsimumuKS_mc_2015_flat.root'\n",
    "    mc_dir_2015 = '/fhgfs/users/chasenberg/mc/2015/jpsimumuks/'\n",
    "    mc_2015 = mc_dir_2015 + mc_file_2015\n",
    "    #read from ROOT-fil\n",
    "    print(\"Reading 2015 mc.\")\n",
    "    df_2015 = rp.read_root(mc_2015,key=tree_data, columns=['B0_FitDaughtersConst_M_flat','piplus_TRACK_Type'], where=hlt2_cut, flatten=False)\n",
    "    df_2015 = df_2015.replace([np.inf, -np.inf], np.nan)\n",
    "    df_2015 = df_2015.dropna()\n",
    "    print(\"The shape of 2015 mc is:\",df_2015.shape)\n",
    "    #directories and files for 2015\n",
    "    mc_file_2016 = 'Bd2JpsimumuKS_mc_2016_flat.root'\n",
    "    mc_dir_2016 = '/fhgfs/users/chasenberg/mc/2016/jpsimumuks/'\n",
    "    mc_2016 = mc_dir_2016 + mc_file_2016\n",
    "    #read from ROOT-file\n",
    "    print(\"Reading 2016 mc.\")\n",
    "    df_2016 = rp.read_root(mc_2016,key=tree_data, columns=['B0_FitDaughtersConst_M_flat','piplus_TRACK_Type'], where=hlt2_cut,flatten=False)\n",
    "    df_2016 = df_2016.replace([np.inf, -np.inf], np.nan)\n",
    "    df_2016 = df_2016.dropna()\n",
    "    print(\"The shape of 2016 mc is:\",df_2016.shape)\n",
    "    print(\"Merging 2015+2016 mc..\")\n",
    "    df_merged_hlt2 = pd.concat([df_2015,df_2016])\n",
    "    \n",
    "    mc_file_2015 = 'Bd2JpsimumuKS_mc_2015_flat.root'\n",
    "    mc_dir_2015 = '/fhgfs/users/chasenberg/mc/2015/jpsimumuks/'\n",
    "    mc_2015 = mc_dir_2015 + mc_file_2015\n",
    "    #read from ROOT-fil\n",
    "    print(\"Reading 2015 mc.\")\n",
    "    df_2015 = rp.read_root(mc_2015,key=tree_data, columns=['B0_FitDaughtersConst_M_flat','piplus_TRACK_Type'], where=cut, flatten=False)\n",
    "    df_2015 = df_2015.replace([np.inf, -np.inf], np.nan)\n",
    "    df_2015 = df_2015.dropna()\n",
    "    print(\"The shape of 2015 mc is:\",df_2015.shape)\n",
    "    #directories and files for 2015\n",
    "    mc_file_2016 = 'Bd2JpsimumuKS_mc_2016_flat.root'\n",
    "    mc_dir_2016 = '/fhgfs/users/chasenberg/mc/2016/jpsimumuks/'\n",
    "    mc_2016 = mc_dir_2016 + mc_file_2016\n",
    "    #read from ROOT-file\n",
    "    print(\"Reading 2016 mc.\")\n",
    "    df_2016 = rp.read_root(mc_2016,key=tree_data, columns=['B0_FitDaughtersConst_M_flat','piplus_TRACK_Type'], where=cut,flatten=False)\n",
    "    df_2016 = df_2016.replace([np.inf, -np.inf], np.nan)\n",
    "    df_2016 = df_2016.dropna()\n",
    "    print(\"The shape of 2016 mc is:\",df_2016.shape)\n",
    "    print(\"Merging 2015+2016 mc..\")\n",
    "    df_merged_trigger = pd.concat([df_2015,df_2016])\n",
    "   \n",
    "    \n",
    "    efficiency_san = df_merged_sanity.shape[0] / df_merged_nocut.shape[0]\n",
    "    efficiency_trigger = df_merged_trigger.shape[0] / df_merged_sanity.shape[0]\n",
    "    print('the efficiency of the sanity cuts is')\n",
    "    print(efficiency_san)\n",
    "    print('------------------------------------')\n",
    "    print('the efficiency of the trigger requirements is:')\n",
    "    print(efficiency_trigger)\n",
    "    print('DD:')\n",
    "    print(df_merged_trigger.query('piplus_TRACK_Type==5').shape[0] / df_merged_sanity.query('piplus_TRACK_Type==5').shape[0])\n",
    "    print('LL:')\n",
    "    print(df_merged_trigger.query('piplus_TRACK_Type==3').shape[0] / df_merged_sanity.query('piplus_TRACK_Type==3').shape[0])\n",
    "   \n",
    "\n",
    "    ##Print single trigger stages\n",
    "    print('--------------------------------------')\n",
    "    print(\"The efficiencies of the single trigger stages are:\")\n",
    "    print(\"L0\")\n",
    "    efficiency_l0 = df_merged_l0.shape[0] / df_merged_sanity.shape[0]\n",
    "    print('the efficiency of the trigger requirements is:')\n",
    "    print(efficiency_l0)\n",
    "    print('DD:')\n",
    "    print(df_merged_l0.query('piplus_TRACK_Type==5').shape[0] / df_merged_sanity.query('piplus_TRACK_Type==5').shape[0])\n",
    "    print('LL:')\n",
    "    print(df_merged_l0.query('piplus_TRACK_Type==3').shape[0] / df_merged_sanity.query('piplus_TRACK_Type==3').shape[0])\n",
    "    print(\"------------------------------------\")\n",
    "    print(\"HLT1\")\n",
    "    efficiency_hlt1 = df_merged_hlt1.shape[0] / df_merged_sanity.shape[0]\n",
    "    print('the efficiency of the trigger requirements is:')\n",
    "    print(efficiency_hlt1)\n",
    "    print('DD:')\n",
    "    print(df_merged_hlt1.query('piplus_TRACK_Type==5').shape[0] / df_merged_sanity.query('piplus_TRACK_Type==5').shape[0])\n",
    "    print('LL:')\n",
    "    print(df_merged_hlt1.query('piplus_TRACK_Type==3').shape[0] / df_merged_sanity.query('piplus_TRACK_Type==3').shape[0])\n",
    "    print(\"------------------------------------\")\n",
    "    print(\"HLT2\")\n",
    "    efficiency_hlt2 = df_merged_hlt2.shape[0] / df_merged_sanity.shape[0]\n",
    "    print('the efficiency of the trigger requirements is:')\n",
    "    print(efficiency_hlt2)\n",
    "    print('DD:')\n",
    "    print(df_merged_hlt2.query('piplus_TRACK_Type==5').shape[0] / df_merged_sanity.query('piplus_TRACK_Type==5').shape[0])\n",
    "    print('LL:')\n",
    "    print(df_merged_hlt2.query('piplus_TRACK_Type==3').shape[0] / df_merged_sanity.query('piplus_TRACK_Type==3').shape[0])\n",
    "    \n",
    "    \n",
    "    print(\"------------------------------------\")   \n",
    "    \n",
    "    efficiency_san = df_merged_sanity.shape[0] / df_merged_nocut.shape[0]\n",
    "    efficiency_trigger = df_merged_trigger.shape[0] / df_merged_sanity.shape[0]\n",
    "    print('the efficiency of the sanity cuts is')\n",
    "    print(efficiency_san)\n",
    "    print('------------------------------------')\n",
    "    print('the efficiency of the trigger requirements is:')\n",
    "    print(efficiency_trigger)\n",
    "    print('DD:')\n",
    "    print(df_merged_trigger.query('piplus_TRACK_Type==5').shape[0] / df_merged_sanity.query('piplus_TRACK_Type==5').shape[0])\n",
    "    print('LL:')\n",
    "    print(df_merged_trigger.query('piplus_TRACK_Type==3').shape[0] / df_merged_sanity.query('piplus_TRACK_Type==3').shape[0])\n",
    "   \n",
    "\n",
    "    ##Print single trigger stages\n",
    "    print('--------------------------------------')\n",
    "    print(\"The efficiencies of the single trigger stages are:\")\n",
    "    print(\"L0\")\n",
    "    efficiency_l0 = df_merged_l0.shape[0] / df_merged_sanity.shape[0]\n",
    "    print('the efficiency of the trigger requirements is:')\n",
    "    print(efficiency_l0)\n",
    "    print('DD:')\n",
    "    print(df_merged_l0.query('piplus_TRACK_Type==5').shape[0] / df_merged_sanity.query('piplus_TRACK_Type==5').shape[0])\n",
    "    print('LL:')\n",
    "    print(df_merged_l0.query('piplus_TRACK_Type==3').shape[0] / df_merged_sanity.query('piplus_TRACK_Type==3').shape[0])\n",
    "    print(\"------------------------------------\")\n",
    "    print(\"HLT1\")\n",
    "    efficiency_hlt1 = df_merged_hlt1.shape[0] / df_merged_sanity.shape[0]\n",
    "    print('the efficiency of the trigger requirements is:')\n",
    "    print(efficiency_hlt1)\n",
    "    print('DD:')\n",
    "    print(df_merged_hlt1.query('piplus_TRACK_Type==5').shape[0] / df_merged_sanity.query('piplus_TRACK_Type==5').shape[0])\n",
    "    print('LL:')\n",
    "    print(df_merged_hlt1.query('piplus_TRACK_Type==3').shape[0] / df_merged_sanity.query('piplus_TRACK_Type==3').shape[0])\n",
    "    print(\"------------------------------------\")\n",
    "    print(\"HLT2\")\n",
    "    efficiency_hlt2 = df_merged_hlt2.shape[0] / df_merged_sanity.shape[0]\n",
    "    print('the efficiency of the trigger requirements is:')\n",
    "    print(efficiency_hlt2)\n",
    "    print('DD:')\n",
    "    print(df_merged_hlt2.query('piplus_TRACK_Type==5').shape[0] / df_merged_sanity.query('piplus_TRACK_Type==5').shape[0])\n",
    "    print('LL:')\n",
    "    print(df_merged_hlt2.query('piplus_TRACK_Type==3').shape[0] / df_merged_sanity.query('piplus_TRACK_Type==3').shape[0])\n",
    "    \n",
    "    \n",
    "    print(\"------------------------------------\")\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading 2015 data.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-e551fac069dc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     31\u001b[0m     \u001b[1;31m#read from ROOT-fil\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Reading 2015 data.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m     \u001b[0mdf_2015\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_root\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_2015\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtree_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvariables\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflatten\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m     \u001b[0mdf_2015\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_2015\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minf\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m     \u001b[0mdf_2015\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_2015\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/opt/rh/miniconda/envs/py3root6/lib/python3.4/site-packages/root_pandas/readwrite.py\u001b[0m in \u001b[0;36mread_root\u001b[1;34m(paths, key, columns, ignore, chunksize, where, flatten, *args, **kwargs)\u001b[0m\n\u001b[0;32m    164\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mgenchunks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    165\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 166\u001b[1;33m     \u001b[0marr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mroot2array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpaths\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mall_vars\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mselection\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mwhere\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    167\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mflatten\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    168\u001b[0m         \u001b[0marr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdo_flatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/opt/rh/miniconda/envs/py3root6/lib/python3.4/site-packages/root_numpy/_tree.py\u001b[0m in \u001b[0;36mroot2array\u001b[1;34m(filenames, treename, branches, selection, start, stop, step, include_weight, weight_name, cache_size, warn_missing_tree)\u001b[0m\n\u001b[0;32m    207\u001b[0m         \u001b[0mweight_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m         \u001b[0mcache_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 209\u001b[1;33m         warn_missing_tree)\n\u001b[0m\u001b[0;32m    210\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    211\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mflatten\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "create_tuple = True\n",
    "if create_tuple==True:\n",
    "    variables = [\n",
    "    'B0_FitDaughtersConst_M_flat',\n",
    "    'B0_FitDaughtersConst_chi2_flat',\n",
    "    'B0_FitDaughtersConst_IPCHI2_flat',\n",
    "    'B0_FitDaughtersConst_J_psi_1S_IP_flat',   \n",
    "    'B0_FitDaughtersConst_KS0_P1_PT_flat',\n",
    "    'B0_FitDaughtersConst_KS0_P0_PT_flat',  \n",
    "    'B0_FitDaughtersConst_KS0_decayLength_flat',\n",
    "    'B0_FitDaughtersConst_KS0_IP_flat',\n",
    "    'B0_FitDaughtersConst_KS0_P0_IPCHI2_flat', \n",
    "    'B0_FitDaughtersConst_J_psi_1S_IPCHI2_flat',\n",
    "    'idxPV',\n",
    "    'B0_FitDaughtersConst_KS0_P1_PT_flat', \n",
    "    'B0_FitDaughtersConst_KS0_P0_PT_flat',\n",
    "    'B0_FitDaughtersConst_KS0_P0_IPCHI2_flat', \n",
    "    'B0_FitDaughtersConst_KS0_P1_IPCHI2_flat',\n",
    "    'B0_FitDaughtersConst_J_psi_1S_P0_PT_flat', \n",
    "    'B0_FitDaughtersConst_J_psi_1S_P1_PT_flat',\n",
    "    'eventNumber',\n",
    "    'runNumber',\n",
    "    'nPV',\n",
    "    'nPV',\n",
    "    'nTracks',  \n",
    "    ]\n",
    "    #directories and files for 2015\n",
    "    data_file_2015 = 'Bd2JpsimumuKS_mc_2015_flat.root'\n",
    "    data_dir_2015 = '/fhgfs/users/chasenberg/mc/2015/jpsimumuks/'\n",
    "    data_2015 = data_dir_2015 + data_file_2015\n",
    "    #read from ROOT-fil\n",
    "    print(\"Reading 2015 data.\")\n",
    "    df_2015 = rp.read_root(data_2015,key=tree_data, columns=variables, flatten=False)\n",
    "    df_2015 = df_2015.replace([np.inf, -np.inf], np.nan)\n",
    "    df_2015 = df_2015.dropna()\n",
    "    #directories and files for 2015\n",
    "    data_file_2016 = 'Bd2JpsimumuKS_mc_2016_flat.root'\n",
    "    data_dir_2016 = '/fhgfs/users/chasenberg/mc/2016/jpsimumuks/'\n",
    "    data_2016 = data_dir_2016 + data_file_2016\n",
    "    #read from ROOT-file\n",
    "    print(\"Reading 2016 data.\")\n",
    "    df_2016 = rp.read_root(data_2016,key=tree_data, columns=variables, flatten=False)\n",
    "    df_2016 = df_2016.replace([np.inf, -np.inf], np.nan)\n",
    "    df_2016 = df_2016.dropna()\n",
    "    print(\"Merging 2015+2016 data and write to ROOT file.\")\n",
    "    df_merged = pd.concat([df_2015,df_2016])\n",
    "    #Calculate random variable for random selection\n",
    "    np.random.seed(42)\n",
    "    df_merged['idxRandom'] = np.random.choice(2**30, df_merged.shape[0])  \n",
    "    df_merged['idxEventNumber'] = df_merged['eventNumber'] \n",
    "    df_merged['idxRunNumber'] = df_merged['runNumber'] \n",
    "    df_merged.to_root(mc_dir_2015_2016+'Bd2JpsiKS.root',key='Bd2JpsiKS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading 2015 mc.\n",
      "The shape of 2015 mc is: (493853, 70)\n",
      "Reading 2016 mc.\n",
      "The shape of 2016 mc is: (543112, 70)\n",
      "Merging 2015+2016 mc and write to ROOT file.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/rh/miniconda/envs/py3root6/lib/python3.4/site-packages/root_numpy/_tree.py:570: UserWarning: converter for dtype('O') is not implemented (skipping)\n",
      "  _librootnumpy.array2root(arr, filename, treename, mode)\n"
     ]
    }
   ],
   "source": [
    "if create_sanity_tuple==True:\n",
    "    #directories and files for 2015\n",
    "    mc_file_2015 = 'Bd2JpsimumuKS_mc_2015.root'\n",
    "    mc_dir_2015 = '/fhgfs/users/chasenberg/mc/2015/jpsimumuks/work_cut/veto_leaves/wrong_pv_check/'\n",
    "    mc_2015 = mc_dir_2015 + mc_file_2015\n",
    "    #read from ROOT-fil\n",
    "    print(\"Reading 2015 mc.\")\n",
    "    df_2015 = rp.read_root(mc_2015,key=tree_data, columns=variables, flatten=False)\n",
    "    df_2015 = df_2015.replace([np.inf, -np.inf], np.nan)\n",
    "    df_2015 = df_2015.dropna()\n",
    "    print(\"The shape of 2015 mc is:\",df_2015.shape)\n",
    "    #directories and files for 2015\n",
    "    mc_file_2016 = 'Bd2JpsimumuKS_mc_2016.root'\n",
    "    mc_dir_2016 = '/fhgfs/users/chasenberg/mc/2016/jpsimumuks/work_cut/veto_leaves/wrong_pv/'\n",
    "    mc_2016 = mc_dir_2016 + mc_file_2016\n",
    "    #read from ROOT-file\n",
    "    print(\"Reading 2016 mc.\")\n",
    "    df_2016 = rp.read_root(mc_2016,key=tree_data, columns=variables, flatten=False)\n",
    "    df_2016 = df_2016.replace([np.inf, -np.inf], np.nan)\n",
    "    df_2016 = df_2016.dropna()\n",
    "    print(\"The shape of 2016 mc is:\",df_2016.shape)\n",
    "    print(\"Merging 2015+2016 mc and write to ROOT file.\")\n",
    "    df_merged = pd.concat([df_2015,df_2016])\n",
    "    mc_dir_2015_2016 = '/fhgfs/users/chasenberg/mc/2015_2016_merged/jpsimumuks/'\n",
    "    file_name = 'info.txt'\n",
    "    file = open(mc_dir_2015_2016+file_name,'w')  \n",
    "    file.write(\"----------------------------------------\")\n",
    "    file.write(\"The ROOT file has got the calculated L0 veto mass and the pv_z_pull variable, to discriminate between correct/incorrect pvs.\")\n",
    "    file.write('The file'+mc_sanity_cuts+'has got the following cuts:\\n') \n",
    "    file.write(sanity_cuts)\n",
    "    file.write('No other selection has been applied yet.\\n')\n",
    "    size = str(df_merged.shape[0])\n",
    "    file.write('The file has'+size+'entries\\n')\n",
    "    file.write('----------------------------------------')\n",
    "    #Calculate random variable for random selection\n",
    "    np.random.seed(42)\n",
    "    df_merged['idxRandom'] = np.random.choice(2**30, df_merged.shape[0])  \n",
    "    df_merged['idxEventNumber'] = df_merged['eventNumber'] \n",
    "    df_merged['idxRunNumber'] = df_merged['runNumber'] \n",
    "    df_merged.to_root(mc_dir_2015_2016+mc_sanity_cuts,key='Bd2JpsiKS')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Efficiency part"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read selected data: BDT-cut is 1.15 according to FOM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mc_selected = 'Bd2JpsiKS_selected.root'\n",
    "mc_selected = mc_dir_2015_2016 + mc_selected\n",
    "df_selected = rp.read_root(mc_selected)\n",
    "#Calculate true time error \n",
    "#signal_dataframe_wrongPV['Delta_TAU'] = signal_dataframe_wrongPV['B0_FitPVConst_tau_flat']-signal_dataframe_wrongPV['B0_TRUETAU']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['B0_TAGOMEGA_OS', 'B0_TAGDECISION_OS',\n",
       "       'B0_FitDaughtersConst_status_flat', 'B0_FitDaughtersConst_M_flat',\n",
       "       'B0_FitDaughtersConst_chi2_flat', 'B0_FitDaughtersConst_IPCHI2_flat',\n",
       "       'B0_FitDaughtersConst_nDOF_flat', 'B0_FitDaughtersConst_PT_flat',\n",
       "       'B0_FitDaughtersConst_J_psi_1S_P0_PT_flat',\n",
       "       'B0_FitDaughtersConst_J_psi_1S_P1_PT_flat',\n",
       "       'B0_FitDaughtersConst_J_psi_1S_MinIPCHI2anyPV_flat',\n",
       "       'B0_FitDaughtersConst_J_psi_1S_IPCHI2_flat',\n",
       "       'B0_FitDaughtersConst_J_psi_1S_IP_flat',\n",
       "       'B0_FitDaughtersConst_KS0_P1_PT_flat',\n",
       "       'B0_FitDaughtersConst_KS0_P0_PT_flat',\n",
       "       'B0_FitDaughtersConst_KS0_P0_IPCHI2_flat',\n",
       "       'B0_FitDaughtersConst_KS0_P1_IPCHI2_flat',\n",
       "       'B0_FitDaughtersConst_KS0_decayLength_flat',\n",
       "       'B0_FitDaughtersConst_KS0_IP_flat', 'B0_FitPVConst_status_flat',\n",
       "       'B0_FitPVConst_IPCHI2_flat', 'B0_FitPVConst_chi2_flat',\n",
       "       'B0_FitPVConst_nDOF_flat', 'B0_FitPVConst_tauErr_flat',\n",
       "       'B0_FitPVConst_tau_flat', 'B0_FitPVConst_MinIPCHI2anyPV_flat',\n",
       "       'B0_FitPVConst_PV_Z_flat', 'B0_FitPVConst_X_flat',\n",
       "       'B0_FitPVConst_Y_flat', 'B0_FitPVConst_Z_flat',\n",
       "       'B0_FitPVConst_XERR_flat', 'B0_FitPVConst_YERR_flat',\n",
       "       'B0_FitPVConst_ZERR_flat', 'B0_FitPVConst_J_psi_1S_MinIPCHI2anyPV_flat',\n",
       "       'B0_FitPVConst_J_psi_1S_IP_flat', 'B0_FitPVConst_J_psi_1S_IPCHI2_flat',\n",
       "       'B0_FitPVConst_KS0_MinIPCHI2anyPV_flat', 'B0_FitPVConst_KS0_IP_flat',\n",
       "       'B0_FitPVConst_KS0_IPCHI2_flat', 'B0_FitPVConst_KS0_tau_flat',\n",
       "       'B0_FitPVConst_KS0_tauErr_flat', 'B0_FitJpsiPVConst_Z_flat',\n",
       "       'B0_FitJpsiConst_J_psi_1S_MinIPCHI2anyPV_flat', 'B0_BKGCAT',\n",
       "       'B0_TRUETAU', 'B0_TAU', 'B0_TAUERR', 'B0_MINIPCHI2', 'pv_z_pull',\n",
       "       'piplus_TRACK_Type', 'piminus_MINIPCHI2', 'piplus_MINIPCHI2',\n",
       "       'muminus_MINIPCHI2', 'muplus_MINIPCHI2', 'piplus_ProbNNp',\n",
       "       'piminus_ProbNNp', 'varLambda0MassHypo_ppluspiminus',\n",
       "       'varLambda0MassHypo_pminuspiplus', 'eventNumber', 'runNumber',\n",
       "       'B0_LOKI_ETA', 'B0_LOKI_PHI', 'nPV', 'nTracks', 'idxPV', 'B0_TRUEID',\n",
       "       'idxRandom', 'idxEventNumber', 'idxRunNumber',\n",
       "       'B0_FitDaughtersConst_KS0_min_PT', 'test_IP',\n",
       "       'B0_FitDaughtersConst_J_psi_1S_min_PT', 'B0_FitPVConst_KS0_tau_dimless',\n",
       "       'Delta_TAU_dtf', 'Delta_TAU', 'BDTresponse'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_selected.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mc_pv_selected = 'Bd2JpsiKS_pv_selected.root'\n",
    "mc_pv_selected = mc_dir_2015_2016 + mc_pv_selected\n",
    "df_pv_selected = rp.read_root(mc_pv_selected)\n",
    "#Calculate true time error \n",
    "#signal_dataframe_wrongPV['Delta_TAU'] = signal_dataframe_wrongPV['B0_FitPVConst_tau_flat']-signal_dataframe_wrongPV['B0_TRUETAU']pv_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best PV cut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Check best PV cut\n",
    "efficiency = df_selected.query('idxPV==0').shape[0]/df_selected.shape[0]\n",
    "print(\"The efficency of the best pv selection is:\")\n",
    "print(efficiency)\n",
    "print(\"----------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write a best PV selected dataset to root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "l0_cut =  '((abs(1115.683-varLambda0MassHypo_ppluspiminus)>17)|piplus_ProbNNp<0.4)&((abs(1115.683-varLambda0MassHypo_pminuspiplus)>17)|(piminus_ProbNNp<0.4))'\n",
    "pv_cut = \"&idxPV==0\"# \"&B0_FitPVConst_MinIPCHI2anyPV_flat>6\"\n",
    "df_pv_selected.query(l0_cut + pv_cut).to_root(mc_dir_2015_2016+'Bd2JpsiKS_bestPV.root', key='Bd2JpsiKS')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check efficiencies of all selection steps\n",
    "================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BDT cut of 1.15\n",
    "------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "efficiency =  df_selected.query('idxPV==0').shape[0]/df_merged.query('idxPV==0').shape[0]\n",
    "print(\"The efficency of the BDT cut is:\")\n",
    "print(efficiency)\n",
    "print(\"----------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply the L0 veto\n",
    "--------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "l0_cut =  '((abs(1115.683-varLambda0MassHypo_ppluspiminus)>17)|piplus_ProbNNp<0.4)&((abs(1115.683-varLambda0MassHypo_pminuspiplus)>17)|(piminus_ProbNNp<0.4))'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "l0_cutefficiency = df_selected.query(l0_cut).query('idxPV==0').shape[0]/df_selected.query('idxPV==0').shape[0]\n",
    "print(\"The efficency of the L0 veto is:\")\n",
    "print(l0_cutefficiency)\n",
    "print(\"----------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply the MinIPCHI2 cut > 6 and perform a random candidate selection\n",
    "--------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write new ROOT File with L0 veto and MinIPCHI2anyPV cut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "l0_cut =  '((abs(1115.683-varLambda0MassHypo_ppluspiminus)>17)|piplus_ProbNNp<0.4)&((abs(1115.683-varLambda0MassHypo_pminuspiplus)>17)|(piminus_ProbNNp<0.4))'\n",
    "pv_cut = \"\"# \"&B0_FitPVConst_MinIPCHI2anyPV_flat>6\"\n",
    "df_selected.query(l0_cut + pv_cut).to_root(mc_dir_2015_2016+'Bd2JpsiKS_cuts.root', key='Bd2JpsiKS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Call CandidateSelectionGrimReaper\n",
      "Start CandidateSelectionGrimReaper!\n",
      "Wait for GrimReaper\n",
      "GrimReaper hopefully finished\n"
     ]
    }
   ],
   "source": [
    "import os, subprocess\n",
    "if create_randomSel_tuple==True:\n",
    "    print('INFO: Call CandidateSelectionGrimReaper', flush=True)\n",
    "    my_env = os.environ.copy()\n",
    "    my_env['PATH'] = '/usr/local/bin:/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/sbin:/home/chasenberg/bin'\n",
    "    my_env['LD_LIBRARY_PATH'] = '/usr/local/lib'\n",
    "    my_env['script'] = '/home/chasenberg/repos/b2cc_sin2beta_run2/notebooks/selection'\n",
    "    print(\"Start CandidateSelectionGrimReaper!\")\n",
    "    my_command = 'source /lhcbsoft/LHCbSoftwareSetup.sh &&' \\\n",
    "             'lb-run DaVinci/v41r2 $BASH -c \"' \\\n",
    "             'echo $PATH && ' \\\n",
    "             'source /doosoft/InstallDooSoftware/LoadDooSoftware && CandidateSelectionGrimReaper /fhgfs/users/chasenberg/mc/2015_2016_merged/jpsimumuks/Bd2JpsiKS_pv_selected.root Bd2JpsiKS /fhgfs/users/chasenberg/mc/2015_2016_merged/jpsimumuks/Bd2JpsiKS_random.root Bd2JpsiKS \"idxRandom\"\"'                     \n",
    "    subprocess.Popen([my_command], env=my_env, shell=True)\n",
    "    print(\"Wait for GrimReaper\")\n",
    "    time.sleep(120.0)    # pause 5.5 seconds\n",
    "    print(\"GrimReaper hopefully finished\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Efficiency of random selection\n",
    "-------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_random_sel = rp.read_root(mc_dir_2015_2016 + mc_random, key='Bd2JpsiKS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "eff = df_random_sel.shape[0]/df_selected.query(l0_cut+'&idxPV==0').shape[0]\n",
    "print(eff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
